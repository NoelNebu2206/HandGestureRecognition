# Real-Time Gesture-Controlled Audio Synthesis

## Project Description
This project introduces an advanced gesture-controlled music system that leverages the MobileNetV2 architecture and OpenCV for instantaneous hand gesture recognition. The system allows users to dynamically manipulate music through an intuitive camera interface, providing a unique and interactive audio experience.

## Features
- Real-time hand gesture recognition for audio control
- Intuitive camera interface for gesture input
- Dynamic music manipulation based on recognized gestures
- Utilization of MobileNetV2 for efficient gesture recognition

## Technologies Used
- Python
- TensorFlow/Keras (MobileNetV2)
- OpenCV
- Audio processing libraries (e.g., PyAudio, Librosa)

## Usage
- Launch the application and position your hand within the camera frame.
- Perform predefined hand gestures to control various aspects of the audio synthesis, such as volume, pitch, and tempo.
